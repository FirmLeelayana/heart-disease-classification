{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict whether a patient has heart disease or not!\n",
    "\n",
    "#Load data from excel spreadsheet\n",
    "import csv\n",
    "spreadsheet = open('heart_disease_dataset.csv', encoding = 'utf-8')\n",
    "csv_data = csv.reader(spreadsheet)\n",
    "spreadsheet_list = list(csv_data)\n",
    "cv_set = spreadsheet_list[200:250]\n",
    "test_set = spreadsheet_list[250:]\n",
    "spreadsheet_list = spreadsheet_list[:200]\n",
    "spreadsheet.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the sigmoid function\n",
    "import math\n",
    "import numpy as np\n",
    "def sigmoid(z):\n",
    "    return (1/(1+np.exp(-z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add x0 = 1 to the dataset\n",
    "import numpy as np\n",
    "\n",
    "#remove the header titles\n",
    "spreadsheet_list = spreadsheet_list[1:]\n",
    "\n",
    "#Add x0 to array\n",
    "row_num = len(spreadsheet_list)\n",
    "x0 = np.ones((row_num, 1))\n",
    "spreadsheet_list = list(np.append(x0, np.array(spreadsheet_list), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert str to float for each spreadsheet number\n",
    "new_spr_list = []\n",
    "for row in spreadsheet_list:\n",
    "    add_list = []\n",
    "    for col in row:\n",
    "        add_list.append(float(col))\n",
    "    new_spr_list.append(add_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove y from the spreadsheet data\n",
    "final_spr_list = []\n",
    "for row in new_spr_list:\n",
    "    final_spr_list.append(row[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          0.93704365  0.6397503  ... -0.71110168  0.5921623\n",
      "  -0.90638782]\n",
      " [ 1.          1.39047024  0.6397503  ...  2.36518603 -0.93823118\n",
      "   1.09773636]\n",
      " [ 1.          1.39047024  0.6397503  ...  1.33975679  1.10229347\n",
      "   1.09773636]\n",
      " ...\n",
      " [ 1.          0.48361706  0.6397503  ... -0.71110168 -0.93823118\n",
      "   1.09773636]\n",
      " [ 1.         -0.53659278 -1.55525504 ... -0.71110168 -0.93823118\n",
      "  -0.90638782]\n",
      " [ 1.          1.0504003  -1.55525504 ... -0.71110168 -0.93823118\n",
      "  -0.90638782]]\n"
     ]
    }
   ],
   "source": [
    "#Mean normalisation and feature scaling\n",
    "from statistics import *\n",
    "\n",
    "#Useful variables\n",
    "rows_num = len(final_spr_list)\n",
    "col_num = len(final_spr_list[0])\n",
    "\n",
    "#Remove x0 first\n",
    "final_spr_list2 = []\n",
    "for row in new_spr_list:\n",
    "    final_spr_list2.append(row[1:])\n",
    "    \n",
    "#calculating mean\n",
    "def cal_mean(spreadsheet_data, col, rows):\n",
    "    'Returns row vector of mean for each column, size 1xm, takes in spreadsheet data, col, row'\n",
    "    initial_sum = np.array([0.0]*col)\n",
    "    for row in spreadsheet_data:\n",
    "        initial_sum += np.array(row)\n",
    "    col_mean = initial_sum/rows\n",
    "    return col_mean\n",
    "\n",
    "col_mean = cal_mean(final_spr_list2, col_num, rows_num)\n",
    "\n",
    "#calculating stdev\n",
    "def stdevlist(spreadsheet_data, col, rows):\n",
    "    'Returns 1xm row vector of the stdev for each column, takes in spreadsheet data, col, row'\n",
    "    spreadsheet_data = np.array(spreadsheet_data)\n",
    "    stdev_list = np.array([0.0]*col)\n",
    "    for i in range(col):\n",
    "        stdev_list[i] = stdev(spreadsheet_data[:,i])\n",
    "    return stdev_list\n",
    "        \n",
    "stdev_list = stdevlist(final_spr_list2, col_num, rows_num)\n",
    " \n",
    "#feature scaling\n",
    "def feature_scaling(stdeviation, mean, data):\n",
    "    'Takes in mean and stdeviation row vector 1xm and data, returns feature scaled numpy matrix'\n",
    "    feature_scaled = np.zeros((rows_num, col_num))\n",
    "    for row in range(rows_num):\n",
    "        for col in range(col_num):\n",
    "            feature_scaled[row, col] = (data[row, col] - mean[col]) / stdev_list[col]\n",
    "    return np.array(feature_scaled)\n",
    "            \n",
    "#fs_list is feature scaled and mean normalised numpy array of data\n",
    "fs_list = feature_scaling(stdev_list, col_mean, np.array(final_spr_list2))\n",
    "\n",
    "#add back x0\n",
    "x0 = np.ones((row_num, 1))\n",
    "fs_list = np.append(x0, fs_list, axis=1)\n",
    "print(fs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise weight vectors\n",
    "rows_num = len(fs_list)\n",
    "col_num = len(fs_list[0])\n",
    "\n",
    "theta = np.zeros((col_num,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting y from the data (as numpy array)\n",
    "new_spr_list = np.array(new_spr_list)\n",
    "y_vector = new_spr_list[:,-1]\n",
    "y_vector = np.reshape(y_vector, (rows_num, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45babfafc9814d86b7f4844ab4c831ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='feature1', max=13, min=1), IntSlider(value=5, descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualising data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "\n",
    "#Create separate numpy arrays for y=0 data and y=1 data\n",
    "def separate_data(numpy_data, y, col_num):\n",
    "    'returns 2 vectors for y = 0 data and y = 1 data, accepts numpy array'\n",
    "    y0_data = np.empty((0, col_num))\n",
    "    y1_data = np.empty((0, col_num))\n",
    "    for i in range(rows_num):\n",
    "        if int(y[i]) == 1:\n",
    "            y1_data = np.append(y1_data, np.array([numpy_data[i,:]]), axis = 0)\n",
    "        elif int(y[i]) == 0:\n",
    "            y0_data = np.append(y0_data, np.array([numpy_data[i,:]]), axis = 0)\n",
    "        else:\n",
    "            pass\n",
    "    return y0_data, y1_data\n",
    "        \n",
    "y0_data, y1_data = separate_data(fs_list, y_vector, col_num)\n",
    "\n",
    "def visualise_data(feature1 = 1, feature2 = 5):\n",
    "    'plots feature1 against feature2 as scatterplot, takes in numpy arrays'\n",
    "    feature1_plots0 = y0_data[:,int(feature1)]\n",
    "    feature2_plots0 = y0_data[:,int(feature2)]\n",
    "    \n",
    "    feature1_plots1 = y1_data[:,int(feature1)]\n",
    "    feature2_plots1 = y1_data[:,int(feature2)]\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot()\n",
    "    ax.scatter(feature1_plots0, feature2_plots0, color='r')\n",
    "    ax.scatter(feature1_plots1, feature2_plots1, color='b')\n",
    "    ax.set_xlabel(f'Feature {feature1}')\n",
    "    ax.set_ylabel(f'Feature {feature2}')\n",
    "    ax.set_title(f'Feature {feature1} against Feature {feature2}')\n",
    "    plt.xlim(-5, 5)\n",
    "    plt.ylim(-5, 5)\n",
    "    plt.show()\n",
    "\n",
    "#visualise_data(y0_data, y1_data, 1, 5)\n",
    "interact(visualise_data, feature1 =(1, 13, 1), feature2=(1, 13, 1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f229bf7badc46cda76ccaf2c7490d23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=300, description='number_it', max=1000, min=1, step=50), FloatSlider(val…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# cost function\n",
    "\n",
    "def init_weights():\n",
    "    rows_num = len(fs_list)\n",
    "    col_num = len(fs_list[0])\n",
    "    theta = np.zeros((col_num,1))\n",
    "    return theta\n",
    "\n",
    "def cost_function(data, theta, y, lam = 0.03):\n",
    "    'calculates the cost function for a given theta weight matrix'\n",
    "    hypothesis = sigmoid(data @ theta)\n",
    "    m = rows_num\n",
    "    sumofweights = np.transpose(theta) @ theta\n",
    "    sumofweights = sumofweights[0]\n",
    "    cost = (1/m) * (-np.transpose(y) @ np.log(hypothesis) - np.transpose((1 - y))@ np.log(1-hypothesis)) + (lam/m) * sumofweights\n",
    "    return cost[0][0]\n",
    "\n",
    "def gradient_descent(data, theta, y, alpha, lam = 0.03):\n",
    "    hypothesis = sigmoid(data @ theta)\n",
    "    m = rows_num\n",
    "    theta_temp = theta\n",
    "    theta_temp[0] = 0\n",
    "    theta -= (alpha/m) * np.transpose(data) @ (hypothesis - y) + (lam/m) * theta_temp\n",
    "    return theta\n",
    "\n",
    "def iteration(number_it = 300, alpha = 0.01, lam = 0.03):\n",
    "    theta = init_weights()\n",
    "    cost_list = []\n",
    "    for i in range(number_it):\n",
    "        cost = cost_function(fs_list, theta, y_vector, lam)\n",
    "        theta = gradient_descent(fs_list, theta, y_vector, alpha, lam)\n",
    "        cost_list.append(cost)\n",
    "    \n",
    "    x = np.arange(1, number_it + 1, 1)\n",
    "    plt.plot(x, np.array(cost_list))\n",
    "    plt.ylabel('Cost')\n",
    "    plt.xlabel('Number of iterations')\n",
    "    plt.title('Cost against iteration')\n",
    "    plt.show()\n",
    "\n",
    "#interactive plot of iteration number, learning rate, and cost over iteration\n",
    "interact(iteration, number_it =(1, 1000, 50), alpha=(0, 1, 0.01), lam = (0, 1, 0.01));\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-5.61325367e-04]\n",
      " [ 5.59754460e-02]\n",
      " [ 3.19850423e-01]\n",
      " [ 4.62105636e-01]\n",
      " [ 2.17014826e-01]\n",
      " [ 1.58051158e-01]\n",
      " [-1.43509889e-01]\n",
      " [ 2.35989918e-01]\n",
      " [-2.79025816e-01]\n",
      " [ 2.35654903e-01]\n",
      " [ 2.49958920e-01]\n",
      " [ 1.50500510e-01]\n",
      " [ 4.76819535e-01]\n",
      " [ 3.55587609e-01]\n",
      " [ 3.65383881e+00]]\n"
     ]
    }
   ],
   "source": [
    "# cost over time\n",
    "def iteration(number_it = 900, alpha = 0.10, lam = 0):\n",
    "    theta = init_weights()\n",
    "    for i in range(number_it):\n",
    "        cost = cost_function(fs_list, theta, y_vector)\n",
    "        theta = gradient_descent(fs_list, theta, y_vector, alpha)\n",
    "    return theta\n",
    "\n",
    "theta_values = iteration()\n",
    "print(theta_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01265467078971175\n"
     ]
    }
   ],
   "source": [
    "# Checking against cross validation set\n",
    "\n",
    "#Add x0 to array\n",
    "row_num = len(cv_set)\n",
    "x0 = np.ones((row_num, 1))\n",
    "cv_set = list(np.append(x0, np.array(cv_set), axis=1))\n",
    "\n",
    "#Convert str to float for each spreadsheet number\n",
    "cv_new_list = []\n",
    "for row in cv_set:\n",
    "    add_list = []\n",
    "    for col in row:\n",
    "        add_list.append(float(col))\n",
    "    cv_new_list.append(add_list)\n",
    "\n",
    "#Remove y from the spreadsheet data\n",
    "final_cv_list = []\n",
    "y_cv_values = []\n",
    "for row in cv_new_list:\n",
    "    final_cv_list.append(row[:-1])\n",
    "    y_cv_values.append(row[-1])\n",
    "\n",
    "#Useful variables\n",
    "rows_num = len(final_cv_list)\n",
    "col_num = len(final_cv_list[0])\n",
    "\n",
    "#feature scaling and mean normalisation on cv set\n",
    "#Remove x0 first\n",
    "final_cv_list2 = []\n",
    "for row in cv_new_list:\n",
    "    final_cv_list2.append(row[1:])\n",
    "\n",
    "#perform feature scaling and mean normalisation\n",
    "cv_fs_list = feature_scaling(stdev_list, col_mean, np.array(final_cv_list2))\n",
    "\n",
    "#add back x0\n",
    "x0 = np.ones((row_num, 1))\n",
    "cv_fs_list = np.append(x0, cv_fs_list, axis=1)\n",
    "\n",
    "def cv_check(data, theta, y):\n",
    "    'calculates the cost function for a given theta weight matrix'\n",
    "    hypothesis = sigmoid(data @ theta)\n",
    "    m = rows_num\n",
    "    lam = 0\n",
    "    sumofweights = np.transpose(theta) @ theta\n",
    "    sumofweights = sumofweights[0]\n",
    "    cost = (1/m) * (-np.transpose(y) @ np.log(hypothesis) - np.transpose((1 - y))@ np.log(1-hypothesis))+ (lam/m) * sumofweights\n",
    "    return cost[0]\n",
    "\n",
    "cv_cost = cv_check(np.array(cv_fs_list), np.array(theta_values), np.array(y_cv_values))\n",
    "print(cv_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 0, probability: [0.17861591]\n",
      "Actual value: 0.0\n",
      "Prediction: 0, probability: [0.00787536]\n",
      "Actual value: 0.0\n",
      "Prediction: 0, probability: [0.01549401]\n",
      "Actual value: 0.0\n",
      "Prediction: 0, probability: [0.0032894]\n",
      "Actual value: 0.0\n",
      "Prediction: 0, probability: [0.01788543]\n",
      "Actual value: 0.0\n",
      "Prediction: 0, probability: [0.01620768]\n",
      "Actual value: 0.0\n",
      "Prediction: 0, probability: [0.01534767]\n",
      "Actual value: 0.0\n",
      "Prediction: 1, probability: [0.95609703]\n",
      "Actual value: 1.0\n",
      "Prediction: 0, probability: [0.00837491]\n",
      "Actual value: 0.0\n",
      "Prediction: 1, probability: [0.94481881]\n",
      "Actual value: 1.0\n",
      "Prediction: 0, probability: [0.00217296]\n",
      "Actual value: 0.0\n",
      "Prediction: 0, probability: [0.00585564]\n",
      "Actual value: 0.0\n",
      "Prediction: 1, probability: [0.99708682]\n",
      "Actual value: 1.0\n",
      "Prediction: 1, probability: [0.99516274]\n",
      "Actual value: 1.0\n",
      "Prediction: 1, probability: [0.98407712]\n",
      "Actual value: 1.0\n",
      "Prediction: 1, probability: [0.97330188]\n",
      "Actual value: 1.0\n",
      "Prediction: 0, probability: [0.00721848]\n",
      "Actual value: 0.0\n",
      "Prediction: 1, probability: [0.99738757]\n",
      "Actual value: 1.0\n",
      "Prediction: 0, probability: [0.10640843]\n",
      "Actual value: 0.0\n",
      "Prediction: 1, probability: [0.9986554]\n",
      "Actual value: 1.0\n",
      "Prediction: 0, probability: [0.01239711]\n",
      "Actual value: 0.0\n",
      "Prediction: 1, probability: [0.9346178]\n",
      "Actual value: 1.0\n",
      "Prediction: 0, probability: [0.02590758]\n",
      "Actual value: 0.0\n",
      "Prediction: 0, probability: [0.0214885]\n",
      "Actual value: 0.0\n",
      "Prediction: 0, probability: [0.00537643]\n",
      "Actual value: 0.0\n",
      "Prediction: 1, probability: [0.96238979]\n",
      "Actual value: 1.0\n",
      "Prediction: 0, probability: [0.01223992]\n",
      "Actual value: 0.0\n",
      "Prediction: 1, probability: [0.9971793]\n",
      "Actual value: 1.0\n",
      "Prediction: 0, probability: [0.00642556]\n",
      "Actual value: 0.0\n",
      "Prediction: 1, probability: [0.99437249]\n",
      "Actual value: 1.0\n",
      "Prediction: 0, probability: [0.00298236]\n",
      "Actual value: 0.0\n",
      "Prediction: 1, probability: [0.98740941]\n",
      "Actual value: 1.0\n",
      "Prediction: 1, probability: [0.99906926]\n",
      "Actual value: 1.0\n",
      "Prediction: 1, probability: [0.99723428]\n",
      "Actual value: 1.0\n",
      "Prediction: 0, probability: [0.01538218]\n",
      "Actual value: 0.0\n",
      "Prediction: 0, probability: [0.00651242]\n",
      "Actual value: 0.0\n",
      "Prediction: 1, probability: [0.98925863]\n",
      "Actual value: 1.0\n",
      "Prediction: 0, probability: [0.00419662]\n",
      "Actual value: 0.0\n",
      "Prediction: 1, probability: [0.99280711]\n",
      "Actual value: 1.0\n",
      "Prediction: 1, probability: [0.99884205]\n",
      "Actual value: 1.0\n",
      "Prediction: 1, probability: [0.96084148]\n",
      "Actual value: 1.0\n",
      "Prediction: 0, probability: [0.00246914]\n",
      "Actual value: 0.0\n",
      "Prediction: 1, probability: [0.99797296]\n",
      "Actual value: 1.0\n",
      "Prediction: 1, probability: [0.98805577]\n",
      "Actual value: 1.0\n",
      "Prediction: 1, probability: [0.9480273]\n",
      "Actual value: 1.0\n",
      "Prediction: 1, probability: [0.99647454]\n",
      "Actual value: 1.0\n",
      "Prediction: 1, probability: [0.99583078]\n",
      "Actual value: 1.0\n",
      "Prediction: 1, probability: [0.91476095]\n",
      "Actual value: 1.0\n",
      "Accuracy is: 100.0\n"
     ]
    }
   ],
   "source": [
    "# Checking against test data set\n",
    "\n",
    "#Add x0 to array\n",
    "row_num = len(test_set)\n",
    "x0 = np.ones((row_num, 1))\n",
    "test_set = list(np.append(x0, np.array(test_set), axis=1))\n",
    "\n",
    "#Convert str to float for each spreadsheet number\n",
    "test_new_list = []\n",
    "for row in test_set:\n",
    "    add_list = []\n",
    "    for col in row:\n",
    "        add_list.append(float(col))\n",
    "    test_new_list.append(add_list)\n",
    "\n",
    "#Remove y from the spreadsheet data\n",
    "final_set_list = []\n",
    "y_set_values = []\n",
    "for row in test_new_list:\n",
    "    final_set_list.append(row[:-1])\n",
    "    y_set_values.append(row[-1])\n",
    "\n",
    "#Useful variables\n",
    "rows_num = len(final_set_list)\n",
    "col_num = len(final_set_list[0])\n",
    "\n",
    "#feature scaling and mean normalisation on cv set\n",
    "#Remove x0 first\n",
    "final_set_list2 = []\n",
    "for row in test_new_list:\n",
    "    final_set_list2.append(row[1:])\n",
    "\n",
    "#perform feature scaling and mean normalisation\n",
    "test_fs_list = feature_scaling(stdev_list, col_mean, np.array(final_set_list2))\n",
    "\n",
    "#add back x0\n",
    "x0 = np.ones((row_num, 1))\n",
    "test_fs_list = np.append(x0, test_fs_list, axis=1)\n",
    "\n",
    "def prediction(theta, data, value):\n",
    "    global right\n",
    "    right = 0\n",
    "    global wrong\n",
    "    wrong = 0\n",
    "    hypothesis = sigmoid(data @ theta)\n",
    "    if hypothesis >= 0.5:\n",
    "        print(f'Prediction: 1, probability: {hypothesis}')\n",
    "        print(f'Actual value: {y_set_values[value]}')\n",
    "        right +=1\n",
    "    else:\n",
    "        print(f'Prediction: 0, probability: {hypothesis}')\n",
    "        print(f'Actual value: {y_set_values[value]}')\n",
    "        wrong +=1\n",
    "\n",
    "for value in range(len(test_fs_list)):\n",
    "    prediction(np.array(theta_values), test_fs_list[value], value)\n",
    "print(f'Accuracy is: {100*right/(right + wrong)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
